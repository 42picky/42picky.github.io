{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to 42picky","text":""},{"location":"#what-is-42picky","title":"What is 42picky?","text":"<p>42picky hosts a collection of small articles about software development's best and worst practices that hope to become a book in the future.</p> <ul> <li>Embrace KISS and avoid NIH syndrome</li> <li>Keeping local testing close to CI/CD pipelines</li> </ul>"},{"location":"#avoid-and-reduce","title":"Avoid and reduce","text":"<ul> <li>Contribution friction</li> <li>Using non-standard tools, even if cool</li> </ul>"},{"location":"#most-popular-python-tools","title":"Most popular python tools","text":"<ul> <li>tox</li> <li>pre-commit to orchestrate linters</li> <li>flake8</li> <li>pylint</li> <li>mypy</li> <li>black and prettier</li> <li>pytest</li> </ul>"},{"location":"tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p> <p>[TAGS]</p>"},{"location":"anti-patterns/poor-linting/","title":"Poor linting","text":"<p>There should be no debate around the fact that any project that aims to accept contributions from outside should have a linting pipelines setup. Still, the devil is in the details on how this is implemented and in particular how easy is to run the linting locally and get the same results as the CI pipeline.</p>","tags":["linting"]},{"location":"anti-patterns/poor-linting/#each-linter-being-called-manually","title":"Each linter being called manually","text":"<p>If you expect that the contributor will have to call more than one command for linting the project, you are already failed the KISS part.</p> <p>If you need to document how to run the linters in more than a sentence, you probably need to find a way to improve that. The need to document how to contribute is a possible sign that maybe you did not make it easy enough.</p>","tags":["linting"]},{"location":"anti-patterns/poor-linting/#linting-stops-at-the-first-found-error","title":"Linting stops at the first found error","text":"<p>It is not uncommon for projects to have more than a dozen linters configured and if your current linting command stops at the first error, you are forcing the user to run it multiple times without even knowing how much they have to work.</p> <p>Tools like pre-commit can help you to address this because they can act as an orchestrator and they can report all errors at once.</p>","tags":["linting"]},{"location":"anti-patterns/poor-linting/#not-including-isolation-for-the-tools","title":"Not including isolation for the tools","text":"<p>If your local testing does not include containing the tools into a virtual environment and controlling exactly their versioning, your users will struggle to make use of them because their tools will behaver differently.</p>","tags":["linting"]},{"location":"anti-patterns/poor-linting/#avoiding-default-configuration-filenames","title":"Avoiding default configuration filenames","text":"<p>If you are not keeping the tool configuration files in their standard location, other users will fail to load their configuration and have unexpected behavior.</p> <p>If you end up ever having to pass the config file location to such a tool. Keep in mind that user editors and IDEs will have plugins that run the same tools, plugins that will fail to find your \"custom\" configuration file.</p>","tags":["linting"]},{"location":"anti-patterns/poor-linting/#diverging-from-standard-settings","title":"Diverging from standard settings","text":"<p>While disabling some checks that you either do not agree with or you do not want to bother with, is a perfectly valid reason, you should do your best to avoid imposing your personal preferences.</p> <p>A clear example here is the line length limit. Tools like black have a default value of 88 characters, and you should not change this to any other value.</p> <p>If you value contributions, keep in mind that consistency between projects is more important than your personal preferences.</p> <p>The less you diverge from defaults, the easier it will be for others to contribute to your project.</p>","tags":["linting"]},{"location":"anti-patterns/pr-require-approval/","title":"Unfriendly CI","text":"","tags":["hostile-architecture","github"]},{"location":"anti-patterns/pr-require-approval/#require-approval-before-running-ci","title":"Require approval before running CI","text":"<p>If the main CI/CD pipelines are waiting for pre-approval before running, it is a sign that the CI/CD implementation is unfriendly towards new contributors.</p> <p>With GitHub Actions being free for public repositories, there is no real reason to avoid running at least some basic checks on every incoming pull request, without waiting for a human to approve it.</p> <p></p> <p>Many project maintainers were worried about possibly incurring costs or leaks of secrets caused by malicious contributors. The reality is that you should never configure secrets as repository secrets and instead use environments to store secrets. Environments are activated by using <code>environment: env-name</code> in your workflow definitions and they can also be configured to require human approval before running. They are implemented in such a way that an incoming pull request from an outside contributor cannot make use of them, even if they propose a change to the workflow definition.</p> <p>To avoid the problem, be sure that you select the first option for requiring approval, only for GitHub users that are new. The other two options deter new contributors.</p> <p></p>","tags":["hostile-architecture","github"]},{"location":"anti-patterns/signing-disclamers/","title":"Signing disclaimers","text":"<p>One very effective way to deter people from using your software is to request them to sign different disclaimers, a few examples being listed below:</p> <ul> <li>Developer Certificate of Origin (DCO)</li> <li>Contributor License Agreement (CLA)</li> </ul> <p>While it is a very good idea to document the conditions under which you are accepting contributions, preventing people from creating a pull request or from testing it before they sign such a document is a very bad idea.</p> <p>As far as I know, there is no single legal case where the presence of such a document had any effect on the outcome of a lawsuit. You would be adding a wall that does not add any protection, but it does for sure add more friction.</p>","tags":["hostile-architecture"]},{"location":"anti-patterns/unisolated-testing/","title":"Unisolated testing","text":"<p>A very common mistake developers make when configuring the testing for their projects is to perform system or user wide reconfiguration, basically overriding whatever the user running the test has configured.</p> <p>While it is perfectly normal to have some system level requirements and even to have a setup script that attempts to install them when missing, this should not happen without the user's consent.</p> <p>The same setup scripts can be run in unattended mode on CI/CD pipelines, but when run on interactive mode, they should always prompt the user.</p> <p>One of the most common isolation solutions is the use of virtual environments, which exist for most programming languages.</p>"},{"location":"other/schemas/","title":"JSON Validation Schemas","text":"<p>As the mkdocs project does not publish its own JSON Schema for its configuration, you can use the one we create from <code>mkdocs.schema.json</code>.</p> <p>We are fully aware that the schema also depends on plugins so it will never be very comprehensive. However, it is a good starting point for spotting errors, providing autocompletion or documentation tooltips. Feel free to contribute your improvements.</p> <p>If you are using vscode with yaml extension, the schema validation functionality will be automatically enabled.</p>"},{"location":"patterns/formatters/","title":"Automate code formatting","text":"<p>Using linters that enforced code-style is a good practice for any project that aims to have more than one person working on it. However, the way the maintainer chooses to enforce code style does make a big difference, as this could easily create a lot of friction for contributors.</p> <p>Luckily, these days many tools can help with this and which can automatically fix code style even on incoming pull requests.</p> <p>One notable example is pre-commit.ci which you can install as a GitHub App on your repository. This will automatically run and push fixes on top of incoming pull requests. It will never push to your main branch. Nobody should be able to push to your main branch if you configured your repository correctly, including yourself.</p>"},{"location":"principles/kiss/","title":"KISS Principle","text":"<p>KISS principle is one of the most important principles that can be applied in software development. It stands for Keep It Simple, Stupid. and it means that the software should be kept as simple as possible.</p> <p>As a software developer, you should aim to always avoid adding complexity, or over-engineering.</p> <p>Historical figures had their own versions of expressing mainly the same ideas:</p> Leonardo da Vinci <p>Simplicity is the ultimate sophistication</p> Antoine de Saint-Exup\u00e9ry <p>It seems that perfection is reached not when there is nothing left to add, but when there is nothing left to take away</p>"},{"location":"stories/from-sphinx-to-mkdocs/","title":"From sphinx to mkdocs","text":""},{"location":"stories/from-sphinx-to-mkdocs/#from-sphinx-to-mkdocs","title":"From Sphinx to Mkdocs","text":"<p>Note</p> <p>This document is a work in progress, so expect to be updated as my journey continues.</p> <p>I have been seeing the Sphinx documentation ecosystem aging for years, with fewer people wanting to contribute to the system each year. I cannot blame them as the Sphinx is as old as the real Sphinx and it covered a huge number of use cases, some of them no longer being so relevant.</p> <p>One first move was to start using MyST parser and convert most of the documentation from ReST to markdown.</p> <p>Most potential contributors are likely to know Markdown instead of ReST. Markdown also renders nicely even on GitHub, without even needing you to compile the docs.</p>"},{"location":"stories/from-sphinx-to-mkdocs/#challenges","title":"Challenges","text":"<p>The mkdocs ecosystem is new and far more active than sphinx, but it does not come without its own set of challenges.</p>"},{"location":"stories/from-sphinx-to-mkdocs/#one-dependency-too-many","title":"One dependency too many","text":"<p>Soon after starting to use mkdocs, I found that the list of python packages needed to build documentation did grow considerably, reaching almost the same level as with Sphinx.</p> <p>Let's take a look at those that I identified in the last few weeks while converting several python based projects to mkdocs, using the most popular theme mkdocs-material.</p> <pre><code>graph LR;\n\nclassDef theme fill:#060,stroke:#060,color:#fff;\nclassDef plugin fill:#BCF,stroke:#BCF,color:#000;\nclassDef package fill:#AAA,stroke:#AAA,color:#000;\n\n\nmkdocs --&gt; markdown-exec --&gt; pygments-ansi-color;\nmkdocs --&gt; markdown-include;\nmkdocs --&gt; mkdocs-autorefs;\nmkdocs --&gt; mkdocs-exclude;\nmkdocs --&gt; mkdocs-gen-files;\nmkdocs --&gt; mkdocs-git-revision-date-localized-plugin;\nmkdocs --&gt; mkdocs-material;\nmkdocs --&gt; mkdocs-monorepo-plugin;\nmkdocs --&gt; mkdocstrings;\nmkdocs --&gt; pymdown-extensions;\nmkdocs-material --&gt; mkdocs-material-extensions;\nmkdocstrings --&gt; mkdocstrings-python;\n\nmkdocs-material-extensions --&gt; pillow;\nmkdocs-material-extensions --&gt; cairosvg;\npymdown-extensions -.-&gt; pygments;\n\npillow:::package;\ncairosvg:::package;\nmkdocstrings-python:::package;\nmarkdown-exec:::plugin;\nmarkdown-include:::plugin;\nmkdocs-autorefs:::plugin;\nmkdocs-exclude:::plugin;\nmkdocs-gen-files:::plugin;\nmkdocs-git-revision-date-localized-plugin:::plugin;\nmkdocs-monorepo-plugin:::plugin;\nmkdocs:::package;\nmkdocstrings:::plugin;\nmkdocs-material:::theme;\npygments:::package;\nmkdocs-material-extensions:::plugin;\npymdown-extensions:::plugin;\n\n\nclick mkdocs href \"https://www.mkdocs.org/\";\nclick mkdocs-material href \"https://squidfunk.github.io/mkdocs-material/\";\nclick markdown-exec href \"https://github.com/pawamoy/markdown-exec\";\nclick mkdocstrings href \"https://mkdocstrings.github.io/\";\nclick mkdocs-exclude href \"https://github.com/apenwarr/mkdocs-exclude\";\nclick markdown-include href \"https://pypi.org/project/markdown-include/\";\nclick pymdown-extensions href \"https://facelessuser.github.io/pymdown-extensions/\";</code></pre>"},{"location":"stories/from-sphinx-to-mkdocs/#there-will-be-bugs-to-fix","title":"There will be bugs to fix","text":"<p>To put it this way, I already raised several pull requests:</p> <ul> <li>fixes proposed to mkdocstrings and mkdocstrings-python</li> <li>bug reported to Spotify mkdocs-monorepo-plugin but the projects seem to have   a silent community</li> <li>Bug reported again include and snippets plugins as not working with monorepos,   got a \"not my problem\" reply.</li> </ul>"},{"location":"stories/from-sphinx-to-mkdocs/#beware-of-premium-material-theme-features","title":"Beware of premium material theme features","text":"<p>While the material theme is probably the best theme I found for open-source projects, one should also be fully aware that some of the features are limited to the \"insiders\" version, a premium offering that allows the project to stay alive and thrive. One notable mention is that the \"blog\" feature seems to be for insiders only, for now. The others seem reasonable to me, they were cool features but not really what I would call essentials.</p>"},{"location":"stories/from-sphinx-to-mkdocs/#rendering-ansi-output-from-external-commands","title":"Rendering ANSI output from external commands","text":"<p>You need the following steps</p> <ul> <li>Install pygments-ansi-color and [markdown-exec] packages</li> <li>Add <code>markdown-exec</code> to <code>plugins</code> in <code>mkdocs.yml</code></li> <li>Add <code>extra_css</code> for stylesheet like   this   for the colors.</li> <li>Use <code>ansi</code> language for code blocks or <code>result=\"ansi\"</code> for markdown-exec.</li> </ul>"},{"location":"stories/from-sphinx-to-mkdocs/#ansi-content-from-within-markdown-file","title":"ANSI content from within markdown file","text":"<pre><code>The next word is red.\n</code></pre>"},{"location":"stories/from-sphinx-to-mkdocs/#ansi-from-external-commands","title":"ANSI from external commands","text":"<pre><code>                40m   41m   42m   43m   44m   45m   46m   47m\n     m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n    1m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n   30m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n 1;30m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n   31m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n 1;31m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n   32m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n 1;32m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n   33m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n 1;33m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n   34m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n 1;34m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n   35m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n 1;35m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n   36m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n 1;36m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n   37m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n 1;37m   xYz    xYz   xYz   xYz   xYz   xYz   xYz   xYz   xYz \n</code></pre>"},{"location":"stories/from-sphinx-to-mkdocs/#plugins-are-not-always-maintained","title":"Plugins are not always maintained","text":"<ul> <li>The most popular plugin related to combining documentation from multiple   sub-projects into a single site, mkdocs-monorepo-plugin is hosted under   Spotify @backstage organization. Still, despite having over 200 stars,   checking its issue tracker and activity makes me believe that it might not   have a community around it.</li> </ul>"},{"location":"stories/from-sphinx-to-mkdocs/#performance","title":"Performance","text":"<p>While mkdocs was very fast on my initial tests, I did start to spot it as becoming slowing and slower. Luckily it seems that there is <code>--dirtyreload</code> which can be used to speed up the process.</p>"},{"location":"stories/from-sphinx-to-mkdocs/#possible-deeper-issues","title":"Possible deeper issues","text":"<p>While I tried multiple approaches for building a single side out of multiple repositories using mkdocs, I still failed to find a solution that would work and I think that I spotted something that might be the Achilles heel of mkdocs.</p> <p>mkdocs documents use only relative paths and that makes sense to me. Still, it seems that paths are never relative to the current markdown file, but instead they are relative to either the <code>mkdocs.yml</code> or the <code>docs_dir</code>, a folder hosting your documentation, which cannot be the root of the project.</p> <p>And here is where the multi-site problem starts. Even if you bring all the repositories under a file tree, you will still have parts of documentation in multiple different folders. You will no longer have a single <code>docs_dir</code>.</p> <p>As sooner or later you will want to include some examples in your documentation that are taken from standalone files, you will discover new problems:</p> <ul> <li>Your includes no longer work when building the parent site because all   inclusion plugins use paths relative to the <code>mkdocs.yml</code> file. And your parent   <code>mkdocs.yml</code> file will always be at a different level than the child one.</li> <li>mkdocs seems to be quite opinionated on not allowing your to reference files   from outside your <code>docs_dir</code>.</li> </ul> <p>I need to mention that I only tried markdown-include and snippets plugins so far for inclusion. Both broke on a multi-site setup.</p> <p>I am fully aware that I could be holding it wrongly and that is only my lack of knowledge for failing to build multi-site documentation. I guess that I need to dig more to find the first successful example of such a compilation.</p>"},{"location":"stories/from-sphinx-to-mkdocs/#community-interaction","title":"Community interaction","text":"<ul> <li>@squidfunk the author of mkdocs-material is amazing and does a very good job   of helping people with   answers</li> <li>@pawamoy the author of mkdocstrings is also amazing and open to suggestions.   It was a pleasure to interact with him and get several fixes into   mkdocstrings and mkdocstrings-python.</li> <li>Most of the other plugins are less actively maintained, so you will see   tickets not being addressed for many months, if not years on some of them. If   you are lucky you might get some help but I would not bet on it. I am worried   about the fact that there is no single GitHub organization hosting mkdocs   projects, so most plugins are under personal GitHub accounts. This does not   ensure the long-term longevity of these projects. Original authors might have   their priorities changed and you end up with an ecosystem of abandoned   projects and forks. I have seen this happening many times with other similar   ecosystems, enough to suggest mkdocs team do something about this.</li> </ul> <p>It is perfectly sane to assume that your role with a project is not permanent and if you care for your creation to survive the test of time, you better plan from start for it. Hosting your project under an organization that cares about it, is the first step. I know several success stories such @pytest-dev @jazzband and @tox-dev from which we can learn.</p>"},{"location":"stories/from-sphinx-to-mkdocs/#if-you-need-includes-you-are-in-trouble","title":"If you need includes you are in trouble","text":"<p>With Sphinx and MyST I used includes in multiple places, usually to include some readme files from the repository root or to include some standalone examples files into markdown code snippets.</p> <p>While there are at least two solutions for including content with mkdocs, they both are problematic because some decisions that were made regarding how relative paths are computed, something that breaks badly when you try to build a single site out of multiple repositories. I am even wondering if this issue is fixable as it might touch the core concepts on which mkdocs is built.</p> <p>It seems that mkdocs does not provide plugin authors with a way to get the path of the current document. Instead, it provides two paths, the <code>docs_path: docs/</code> and the configuration path. Not only this but it states clearly that the inclusion of files from outside the documentation directory is not encouraged (or supported?).</p> <p>Guess what, when building a single site, your master mkdocs.yml file would be at an upper level than the child ones, so all the paths used by plugins relative to the configuration file will get broken. Also, the same issue will happen to <code>docs_path</code> which now... you have more than one, as your documentation files are spread across multiple places.</p> <p>This journey is still in progress, so over the following weeks, I will have to update the current document, likely to even rewrite it. Hopefully, it would prove to be a good experience. For now, it is interesting and challenging.</p>"}]}